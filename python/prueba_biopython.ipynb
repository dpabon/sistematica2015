{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "\"\"\"\n",
      "Created on  28 04 2015\n",
      "\n",
      "@autor: danne\n",
      "@email: daniel.epm12@gmail.com\n",
      "\n",
      "\"EL ARTE NO ES UN ESPEJO DE LA REALIDAD\n",
      "SINO  UN MARTILLO PARA TRANSFORMARLA\"\n",
      "                        BERTORLT BRECHT\n",
      "\"\"\"\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "'\\nCreated on  28 04 2015\\n\\n@autor: danne\\n@email: daniel.epm12@gmail.com\\n\\n\"EL ARTE NO ES UN ESPEJO DE LA REALIDAD\\nSINO  UN MARTILLO PARA TRANSFORMARLA\"\\n                        BERTORLT BRECHT\\n'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import glob\n",
      "import readline\n",
      "import numpy as np\n",
      "import random\n",
      "from Bio import Entrez"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.chdir(\"/home/tttt/MEGAsync/sistematica/proyecto/data/prueba_piloto/genomas/\")\n",
      "\n",
      "from Bio import Entrez\n",
      "import time\n",
      "Entrez.email =\"eigtw59tyjrt403@gmail.com\"\n",
      "## We instead upload the list of ID beforehand \n",
      "gis=[82943940]\n",
      "request = Entrez.epost(\"nucleotide\",id=\",\".join(map(str,gis)))\n",
      "result = Entrez.read(request)\n",
      "webEnv = result[\"WebEnv\"]\n",
      "queryKey = result[\"QueryKey\"]\n",
      "handle = Entrez.efetch(db=\"nucleotide\",retmode=\"xml\", webenv=webEnv, query_key=queryKey)\n",
      "for r in Entrez.parse(handle):\n",
      "    # Grab the GI \n",
      "    try:\n",
      "        gi=int([x for x in r['GBSeq_other-seqids'] if \"gi\" in x][0].split(\"|\")[1])\n",
      "    except ValueError:\n",
      "        gi=None\n",
      "    prompt=''   \n",
      "    variable=prompt,\">\"+ r[\"GBSeq_primary-accession\"]+\" \"+r[\"GBSeq_definition\"]+\"\\n\"+ str( r[\"GBSeq_sequence\"])\n",
      "    np.savetxt(str(gi)+'.fasta', variable, newline=\"\\n\", fmt=\"%s\")\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-753d5ee915da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mqueryKey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"QueryKey\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nucleotide\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"xml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwebenv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwebEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueryKey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Grab the GI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/Bio/Entrez/Parser.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;31m#Read in another block of the file...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBLOCK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;31m# We have reached the end of the XML file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;31m# fragmentation issues on many platforms.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mchunk_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                 \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;31m# fragmentation issues on many platforms.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print Entrez.parse(handle)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<generator object parse at 0x7ff19852a050>\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.chdir(\"/home/tttt/MEGAsync/sistematica/proyecto/data/prueba_piloto/genomas/\")\n",
      "\n",
      "from Bio import Entrez\n",
      "import time\n",
      "Entrez.email =\"eigtw59tyjrt403@gmail.com\"\n",
      "## We instead upload the list of ID beforehand \n",
      "gis=[82943940]\n",
      "for i in gis:\n",
      "    request = Entrez.epost(\"nucleotide\",id=\",\".join(map(str,gis)))\n",
      "    result = Entrez.read(request)\n",
      "    webEnv = result[\"WebEnv\"]\n",
      "    queryKey = result[\"QueryKey\"]\n",
      "    handle = Entrez.efetch(db=\"nucleotide\",retmode=\"xml\", webenv=webEnv, query_key=queryKey)\n",
      "    for r in Entrez.parse(handle):\n",
      "    # Grab the GI \n",
      "        try:\n",
      "            gi=int([x for x in r['GBSeq_other-seqids'] if \"gi\" in x][0].split(\"|\")[1])\n",
      "        except ValueError:\n",
      "            gi=None\n",
      "        prompt=''   \n",
      "        variable=prompt,\">\"+ r[\"GBSeq_primary-accession\"]+\" \"+r[\"GBSeq_definition\"]+\"\\n\"+ str( r[\"GBSeq_sequence\"])\n",
      "        np.savetxt(str(gi)+'.fasta', variable, newline=\"\\n\", fmt=\"%s\")\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "os.chdir(\"/home/tttt/MEGAsync/sistematica/proyecto/data/prueba_piloto/genomas/\")\n",
      "# Imports\n",
      "from Bio import Entrez\n",
      "from Bio import SeqIO\n",
      "\n",
      "#############################\n",
      "# Retrieve NCBI Data Online #\n",
      "#############################\n",
      "\n",
      "Entrez.email     = \"daniel.epm12@gmail.com\"             # Always tell NCBI who you are\n",
      "genomeAccessions = ['NC_000913', 'NC_002695', 'NC_011750', 'NC_011751', 'NC_017634', 'NC_018658']\n",
      "search           = \" \".join(genomeAccessions)\n",
      "handle           = Entrez.read(Entrez.esearch(db=\"nucleotide\", term=search, retmode=\"xml\"))\n",
      "genomeIds        = handle['IdList']\n",
      "records          = Entrez.efetch(db=\"nucleotide\", id=genomeIds, rettype=\"gb\", retmode=\"text\")\n",
      "\n",
      "###############################\n",
      "# Generate Genome Fasta files #\n",
      "###############################\n",
      "\n",
      "sequences   = []  # store your sequences in a list\n",
      "headers     = []  # store genome names in a list (db_xref ids)\n",
      "\n",
      "for i,record in enumerate(records):\n",
      "\n",
      "    file_out = open(\"genBankRecord_\"+str(i)+\".gb\", \"w\")    # store each genomes .gb in separate files\n",
      "    file_out.write(records.read())\n",
      "    file_out.close()\n",
      "\n",
      "    genomeGenbank   = SeqIO.parse(\"genBankRecord_\"+str(i)+\".gb\", \"genbank\")  # parse in the genbank files\n",
      "    header         = genome.features[0].qualifiers['db_xref'][0]          # name the genome using db_xfred ID\n",
      "    sequence       = genome.seq.tostring()                                # obtain genome sequence\n",
      "\n",
      "    headers.append('>'+header)  # store genome name in list                                     \n",
      "    sequences.append(sequence)  # store sequence in list\n",
      "\n",
      "    \n",
      "    fasta_out = open(\"genome\"+str(i)+\".fasta\",\"w\")     # store each genomes .fasta in separate files\n",
      "    fasta_out.write(header)    # >header ... followed by:\n",
      "    fasta_out.write(sequence)  # sequence ... \n",
      "    fasta_out.close()          # close that .fasta file and move on to next genome\n",
      "records.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'genome' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-19-740074adb7af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mgenomeGenbank\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"genBankRecord_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".gb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"genbank\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# parse in the genbank files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mheader\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mgenome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqualifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'db_xref'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m          \u001b[0;31m# name the genome using db_xfred ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0msequence\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mgenome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                \u001b[0;31m# obtain genome sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'genome' is not defined"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print  record\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LOCUS       NC_000913            4641652 bp    DNA     circular CON 16-DEC-2014\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help (SeqIO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on package Bio.SeqIO in Bio:\n",
        "\n",
        "NAME\n",
        "    Bio.SeqIO - Sequence input/output as SeqRecord objects.\n",
        "\n",
        "FILE\n",
        "    /usr/lib/python2.7/dist-packages/Bio/SeqIO/__init__.py\n",
        "\n",
        "DESCRIPTION\n",
        "    Bio.SeqIO is also documented at U{http://biopython.org/wiki/SeqIO} and by\n",
        "    a whole chapter in our tutorial:\n",
        "     - U{http://biopython.org/DIST/docs/tutorial/Tutorial.html}\n",
        "     - U{http://biopython.org/DIST/docs/tutorial/Tutorial.pdf}\n",
        "    \n",
        "    Input\n",
        "    =====\n",
        "    The main function is Bio.SeqIO.parse(...) which takes an input file handle\n",
        "    (or in recent versions of Biopython alternatively a filename as a string),\n",
        "    and format string.  This returns an iterator giving SeqRecord objects:\n",
        "    \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> for record in SeqIO.parse(\"Fasta/f002\", \"fasta\"):\n",
        "        ...     print(\"%s %i\" % (record.id, len(record)))\n",
        "        gi|1348912|gb|G26680|G26680 633\n",
        "        gi|1348917|gb|G26685|G26685 413\n",
        "        gi|1592936|gb|G29385|G29385 471\n",
        "    \n",
        "    Note that the parse() function will invoke the relevant parser for the\n",
        "    format with its default settings.  You may want more control, in which case\n",
        "    you need to create a format specific sequence iterator directly.\n",
        "    \n",
        "    Input - Single Records\n",
        "    ======================\n",
        "    If you expect your file to contain one-and-only-one record, then we provide\n",
        "    the following 'helper' function which will return a single SeqRecord, or\n",
        "    raise an exception if there are no records or more than one record:\n",
        "    \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> record = SeqIO.read(\"Fasta/f001\", \"fasta\")\n",
        "        >>> print(\"%s %i\" % (record.id, len(record)))\n",
        "        gi|3318709|pdb|1A91| 79\n",
        "    \n",
        "    This style is useful when you expect a single record only (and would\n",
        "    consider multiple records an error).  For example, when dealing with GenBank\n",
        "    files for bacterial genomes or chromosomes, there is normally only a single\n",
        "    record.  Alternatively, use this with a handle when downloading a single\n",
        "    record from the internet.\n",
        "    \n",
        "    However, if you just want the first record from a file containing multiple\n",
        "    record, use the next() function on the iterator (or under Python 2, the\n",
        "    iterator's next() method):\n",
        "    \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> record = next(SeqIO.parse(\"Fasta/f002\", \"fasta\"))\n",
        "        >>> print(\"%s %i\" % (record.id, len(record)))\n",
        "        gi|1348912|gb|G26680|G26680 633\n",
        "    \n",
        "    The above code will work as long as the file contains at least one record.\n",
        "    Note that if there is more than one record, the remaining records will be\n",
        "    silently ignored.\n",
        "    \n",
        "    \n",
        "    Input - Multiple Records\n",
        "    ========================\n",
        "    For non-interlaced files (e.g. Fasta, GenBank, EMBL) with multiple records\n",
        "    using a sequence iterator can save you a lot of memory (RAM).  There is\n",
        "    less benefit for interlaced file formats (e.g. most multiple alignment file\n",
        "    formats).  However, an iterator only lets you access the records one by one.\n",
        "    \n",
        "    If you want random access to the records by number, turn this into a list:\n",
        "    \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> records = list(SeqIO.parse(\"Fasta/f002\", \"fasta\"))\n",
        "        >>> len(records)\n",
        "        3\n",
        "        >>> print(records[1].id)\n",
        "        gi|1348917|gb|G26685|G26685\n",
        "    \n",
        "    If you want random access to the records by a key such as the record id,\n",
        "    turn the iterator into a dictionary:\n",
        "    \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> record_dict = SeqIO.to_dict(SeqIO.parse(\"Fasta/f002\", \"fasta\"))\n",
        "        >>> len(record_dict)\n",
        "        3\n",
        "        >>> print(len(record_dict[\"gi|1348917|gb|G26685|G26685\"]))\n",
        "        413\n",
        "    \n",
        "    However, using list() or the to_dict() function will load all the records\n",
        "    into memory at once, and therefore is not possible on very large files.\n",
        "    Instead, for *some* file formats Bio.SeqIO provides an indexing approach\n",
        "    providing dictionary like access to any record. For example,\n",
        "    \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> record_dict = SeqIO.index(\"Fasta/f002\", \"fasta\")\n",
        "        >>> len(record_dict)\n",
        "        3\n",
        "        >>> print(len(record_dict[\"gi|1348917|gb|G26685|G26685\"]))\n",
        "        413\n",
        "    \n",
        "    Many but not all of the supported input file formats can be indexed like\n",
        "    this. For example \"fasta\", \"fastq\", \"qual\" and even the binary format \"sff\"\n",
        "    work, but alignment formats like \"phylip\", \"clustalw\" and \"nexus\" will not.\n",
        "    \n",
        "    In most cases you can also use SeqIO.index to get the record from the file\n",
        "    as a raw string (not a SeqRecord). This can be useful for example to extract\n",
        "    a sub-set of records from a file where SeqIO cannot output the file format\n",
        "    (e.g. the plain text SwissProt format, \"swiss\") or where it is important to\n",
        "    keep the output 100% identical to the input). For example,\n",
        "    \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> record_dict = SeqIO.index(\"Fasta/f002\", \"fasta\")\n",
        "        >>> len(record_dict)\n",
        "        3\n",
        "        >>> print(record_dict.get_raw(\"gi|1348917|gb|G26685|G26685\").decode())\n",
        "        >gi|1348917|gb|G26685|G26685 human STS STS_D11734.\n",
        "        CGGAGCCAGCGAGCATATGCTGCATGAGGACCTTTCTATCTTACATTATGGCTGGGAATCTTACTCTTTC\n",
        "        ATCTGATACCTTGTTCAGATTTCAAAATAGTTGTAGCCTTATCCTGGTTTTACAGATGTGAAACTTTCAA\n",
        "        GAGATTTACTGACTTTCCTAGAATAGTTTCTCTACTGGAAACCTGATGCTTTTATAAGCCATTGTGATTA\n",
        "        GGATGACTGTTACAGGCTTAGCTTTGTGTGAAANCCAGTCACCTTTCTCCTAGGTAATGAGTAGTGCTGT\n",
        "        TCATATTACTNTAAGTTCTATAGCATACTTGCNATCCTTTANCCATGCTTATCATANGTACCATTTGAGG\n",
        "        AATTGNTTTGCCCTTTTGGGTTTNTTNTTGGTAAANNNTTCCCGGGTGGGGGNGGTNNNGAAA\n",
        "        <BLANKLINE>\n",
        "        >>> print(record_dict[\"gi|1348917|gb|G26685|G26685\"].format(\"fasta\"))\n",
        "        >gi|1348917|gb|G26685|G26685 human STS STS_D11734.\n",
        "        CGGAGCCAGCGAGCATATGCTGCATGAGGACCTTTCTATCTTACATTATGGCTGGGAATC\n",
        "        TTACTCTTTCATCTGATACCTTGTTCAGATTTCAAAATAGTTGTAGCCTTATCCTGGTTT\n",
        "        TACAGATGTGAAACTTTCAAGAGATTTACTGACTTTCCTAGAATAGTTTCTCTACTGGAA\n",
        "        ACCTGATGCTTTTATAAGCCATTGTGATTAGGATGACTGTTACAGGCTTAGCTTTGTGTG\n",
        "        AAANCCAGTCACCTTTCTCCTAGGTAATGAGTAGTGCTGTTCATATTACTNTAAGTTCTA\n",
        "        TAGCATACTTGCNATCCTTTANCCATGCTTATCATANGTACCATTTGAGGAATTGNTTTG\n",
        "        CCCTTTTGGGTTTNTTNTTGGTAAANNNTTCCCGGGTGGGGGNGGTNNNGAAA\n",
        "        <BLANKLINE>\n",
        "    \n",
        "    Here the original file and what Biopython would output differ in the line\n",
        "    wrapping. Also note that under Python 3, the get_raw method will return a\n",
        "    bytes string, hence the use of decode to turn it into a (unicode) string.\n",
        "    This is uncessary on Python 2.\n",
        "    \n",
        "    Also note that the get_raw method will preserve the newline endings. This\n",
        "    example FASTQ file uses Unix style endings (b\"\\n\" only),\n",
        "    \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> fastq_dict = SeqIO.index(\"Quality/example.fastq\", \"fastq\")\n",
        "        >>> len(fastq_dict)\n",
        "        3\n",
        "        >>> raw = fastq_dict.get_raw(\"EAS54_6_R1_2_1_540_792\")\n",
        "        >>> raw.count(b\"\\n\")\n",
        "        4\n",
        "        >>> raw.count(b\"\\r\\n\")\n",
        "        0\n",
        "        >>> b\"\\r\" in raw\n",
        "        False\n",
        "        >>> len(raw)\n",
        "        78\n",
        "    \n",
        "    Here is the same file but using DOS/Windows new lines (b\"\\r\\n\" instead),\n",
        "    \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> fastq_dict = SeqIO.index(\"Quality/example_dos.fastq\", \"fastq\")\n",
        "        >>> len(fastq_dict)\n",
        "        3\n",
        "        >>> raw = fastq_dict.get_raw(\"EAS54_6_R1_2_1_540_792\")\n",
        "        >>> raw.count(b\"\\n\")\n",
        "        4\n",
        "        >>> raw.count(b\"\\r\\n\")\n",
        "        4\n",
        "        >>> b\"\\r\\n\" in raw\n",
        "        True\n",
        "        >>> len(raw)\n",
        "        82\n",
        "    \n",
        "    Because this uses two bytes for each new line, the file is longer than\n",
        "    the Unix equivalent with only one byte.\n",
        "    \n",
        "    \n",
        "    Input - Alignments\n",
        "    ==================\n",
        "    You can read in alignment files as alignment objects using Bio.AlignIO.\n",
        "    Alternatively, reading in an alignment file format via Bio.SeqIO will give\n",
        "    you a SeqRecord for each row of each alignment:\n",
        "    \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> for record in SeqIO.parse(\"Clustalw/hedgehog.aln\", \"clustal\"):\n",
        "        ...     print(\"%s %i\" % (record.id, len(record)))\n",
        "        gi|167877390|gb|EDS40773.1| 447\n",
        "        gi|167234445|ref|NP_001107837. 447\n",
        "        gi|74100009|gb|AAZ99217.1| 447\n",
        "        gi|13990994|dbj|BAA33523.2| 447\n",
        "        gi|56122354|gb|AAV74328.1| 447\n",
        "    \n",
        "    \n",
        "    Output\n",
        "    ======\n",
        "    Use the function Bio.SeqIO.write(...), which takes a complete set of\n",
        "    SeqRecord objects (either as a list, or an iterator), an output file handle\n",
        "    (or in recent versions of Biopython an output filename as a string) and of\n",
        "    course the file format::\n",
        "    \n",
        "        from Bio import SeqIO\n",
        "        records = ...\n",
        "        SeqIO.write(records, \"example.faa\", \"fasta\")\n",
        "    \n",
        "    Or, using a handle::\n",
        "    \n",
        "        from Bio import SeqIO\n",
        "        records = ...\n",
        "        with open(\"example.faa\", \"w\") as handle:\n",
        "            SeqIO.write(records, handle, \"fasta\")\n",
        "    \n",
        "    You are expected to call this function once (with all your records) and if\n",
        "    using a handle, make sure you close it to flush the data to the hard disk.\n",
        "    \n",
        "    \n",
        "    Output - Advanced\n",
        "    =================\n",
        "    The effect of calling write() multiple times on a single file will vary\n",
        "    depending on the file format, and is best avoided unless you have a strong\n",
        "    reason to do so.\n",
        "    \n",
        "    If you give a filename, then each time you call write() the existing file\n",
        "    will be overwriten. For sequential files formats (e.g. fasta, genbank) each\n",
        "    \"record block\" holds a single sequence.  For these files it would probably\n",
        "    be safe to call write() multiple times by re-using the same handle.\n",
        "    \n",
        "    \n",
        "    However, trying this for certain alignment formats (e.g. phylip, clustal,\n",
        "    stockholm) would have the effect of concatenating several multiple sequence\n",
        "    alignments together.  Such files are created by the PHYLIP suite of programs\n",
        "    for bootstrap analysis, but it is clearer to do this via Bio.AlignIO instead.\n",
        "    \n",
        "    \n",
        "    Conversion\n",
        "    ==========\n",
        "    The Bio.SeqIO.convert(...) function allows an easy interface for simple\n",
        "    file format conversions. Additionally, it may use file format specific\n",
        "    optimisations so this should be the fastest way too.\n",
        "    \n",
        "    In general however, you can combine the Bio.SeqIO.parse(...) function with\n",
        "    the Bio.SeqIO.write(...) function for sequence file conversion. Using\n",
        "    generator expressions or generator functions provides a memory efficient way\n",
        "    to perform filtering or other extra operations as part of the process.\n",
        "    \n",
        "    \n",
        "    File Formats\n",
        "    ============\n",
        "    When specifying the file format, use lowercase strings.  The same format\n",
        "    names are also used in Bio.AlignIO and include the following:\n",
        "    \n",
        "     - abif    - Applied Biosystem's sequencing trace format\n",
        "     - ace     - Reads the contig sequences from an ACE assembly file.\n",
        "     - embl    - The EMBL flat file format. Uses Bio.GenBank internally.\n",
        "     - fasta   - The generic sequence file format where each record starts with\n",
        "                 an identifer line starting with a \">\" character, followed by\n",
        "                 lines of sequence.\n",
        "     - fastq   - A \"FASTA like\" format used by Sanger which also stores PHRED\n",
        "                 sequence quality values (with an ASCII offset of 33).\n",
        "     - fastq-sanger - An alias for \"fastq\" for consistency with BioPerl and EMBOSS\n",
        "     - fastq-solexa - Original Solexa/Illumnia variant of the FASTQ format which\n",
        "                 encodes Solexa quality scores (not PHRED quality scores) with an\n",
        "                 ASCII offset of 64.\n",
        "     - fastq-illumina - Solexa/Illumina 1.3 to 1.7 variant of the FASTQ format\n",
        "                 which encodes PHRED quality scores with an ASCII offset of 64\n",
        "                 (not 33). Note as of version 1.8 of the CASAVA pipeline Illumina\n",
        "                 will produce FASTQ files using the standard Sanger encoding.\n",
        "     - genbank - The GenBank or GenPept flat file format.\n",
        "     - gb      - An alias for \"genbank\", for consistency with NCBI Entrez Utilities\n",
        "     - ig      - The IntelliGenetics file format, apparently the same as the\n",
        "                 MASE alignment format.\n",
        "     - imgt    - An EMBL like format from IMGT where the feature tables are more\n",
        "                 indented to allow for longer feature types.\n",
        "     - phd     - Output from PHRED, used by PHRAP and CONSED for input.\n",
        "     - pir     - A \"FASTA like\" format introduced by the National Biomedical\n",
        "                 Research Foundation (NBRF) for the Protein Information Resource\n",
        "                 (PIR) database, now part of UniProt.\n",
        "     - seqxml  - SeqXML, simple XML format described in Schmitt et al (2011).\n",
        "     - sff     - Standard Flowgram Format (SFF), typical output from Roche 454.\n",
        "     - sff-trim - Standard Flowgram Format (SFF) with given trimming applied.\n",
        "     - swiss   - Plain text Swiss-Prot aka UniProt format.\n",
        "     - tab     - Simple two column tab separated sequence files, where each\n",
        "                 line holds a record's identifier and sequence. For example,\n",
        "                 this is used as by Aligent's eArray software when saving\n",
        "                 microarray probes in a minimal tab delimited text file.\n",
        "     - qual    - A \"FASTA like\" format holding PHRED quality values from\n",
        "                 sequencing DNA, but no actual sequences (usually provided\n",
        "                 in separate FASTA files).\n",
        "     - uniprot-xml - The UniProt XML format (replacement for the SwissProt plain\n",
        "                 text format which we call \"swiss\")\n",
        "    \n",
        "    Note that while Bio.SeqIO can read all the above file formats, it cannot\n",
        "    write to all of them.\n",
        "    \n",
        "    You can also use any file format supported by Bio.AlignIO, such as \"nexus\",\n",
        "    \"phlip\" and \"stockholm\", which gives you access to the individual sequences\n",
        "    making up each alignment as SeqRecords.\n",
        "\n",
        "PACKAGE CONTENTS\n",
        "    AbiIO\n",
        "    AceIO\n",
        "    FastaIO\n",
        "    IgIO\n",
        "    InsdcIO\n",
        "    Interfaces\n",
        "    PdbIO\n",
        "    PhdIO\n",
        "    PirIO\n",
        "    QualityIO\n",
        "    SeqXmlIO\n",
        "    SffIO\n",
        "    SwissIO\n",
        "    TabIO\n",
        "    UniprotIO\n",
        "    _convert\n",
        "    _index\n",
        "\n",
        "FUNCTIONS\n",
        "    convert(in_file, in_format, out_file, out_format, alphabet=None)\n",
        "        Convert between two sequence file formats, return number of records.\n",
        "        \n",
        "         - in_file - an input handle or filename\n",
        "         - in_format - input file format, lower case string\n",
        "         - out_file - an output handle or filename\n",
        "         - out_format - output file format, lower case string\n",
        "         - alphabet - optional alphabet to assume\n",
        "        \n",
        "        NOTE - If you provide an output filename, it will be opened which will\n",
        "        overwrite any existing file without warning. This may happen if even\n",
        "        the conversion is aborted (e.g. an invalid out_format name is given).\n",
        "        \n",
        "        For example, going from a filename to a handle:\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> try:\n",
        "        ...     from StringIO import StringIO # Python 2\n",
        "        ... except ImportError:\n",
        "        ...     from io import StringIO # Python 3\n",
        "        ...\n",
        "        >>> handle = StringIO(\"\")\n",
        "        >>> SeqIO.convert(\"Quality/example.fastq\", \"fastq\", handle, \"fasta\")\n",
        "        3\n",
        "        >>> print(handle.getvalue())\n",
        "        >EAS54_6_R1_2_1_413_324\n",
        "        CCCTTCTTGTCTTCAGCGTTTCTCC\n",
        "        >EAS54_6_R1_2_1_540_792\n",
        "        TTGGCAGGCCAAGGCCGATGGATCA\n",
        "        >EAS54_6_R1_2_1_443_348\n",
        "        GTTGCTTCTGGCGTGGGTGGGGGGG\n",
        "        <BLANKLINE>\n",
        "    \n",
        "    index(filename, format, alphabet=None, key_function=None)\n",
        "        Indexes a sequence file and returns a dictionary like object.\n",
        "        \n",
        "         - filename - string giving name of file to be indexed\n",
        "         - format   - lower case string describing the file format\n",
        "         - alphabet - optional Alphabet object, useful when the sequence type\n",
        "                      cannot be automatically inferred from the file itself\n",
        "                      (e.g. format=\"fasta\" or \"tab\")\n",
        "         - key_function - Optional callback function which when given a\n",
        "                      SeqRecord identifier string should return a unique\n",
        "                      key for the dictionary.\n",
        "        \n",
        "        This indexing function will return a dictionary like object, giving the\n",
        "        SeqRecord objects as values:\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> records = SeqIO.index(\"Quality/example.fastq\", \"fastq\")\n",
        "        >>> len(records)\n",
        "        3\n",
        "        >>> sorted(records)\n",
        "        ['EAS54_6_R1_2_1_413_324', 'EAS54_6_R1_2_1_443_348', 'EAS54_6_R1_2_1_540_792']\n",
        "        >>> print(records[\"EAS54_6_R1_2_1_540_792\"].format(\"fasta\"))\n",
        "        >EAS54_6_R1_2_1_540_792\n",
        "        TTGGCAGGCCAAGGCCGATGGATCA\n",
        "        <BLANKLINE>\n",
        "        >>> \"EAS54_6_R1_2_1_540_792\" in records\n",
        "        True\n",
        "        >>> print(records.get(\"Missing\", None))\n",
        "        None\n",
        "        \n",
        "        If the file is BGZF compressed, this is detected automatically. Ordinary\n",
        "        GZIP files are not supported:\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> records = SeqIO.index(\"Quality/example.fastq.bgz\", \"fastq\")\n",
        "        >>> len(records)\n",
        "        3\n",
        "        >>> print(records[\"EAS54_6_R1_2_1_540_792\"].seq)\n",
        "        TTGGCAGGCCAAGGCCGATGGATCA\n",
        "        \n",
        "        Note that this pseudo dictionary will not support all the methods of a\n",
        "        true Python dictionary, for example values() is not defined since this\n",
        "        would require loading all of the records into memory at once.\n",
        "        \n",
        "        When you call the index function, it will scan through the file, noting\n",
        "        the location of each record. When you access a particular record via the\n",
        "        dictionary methods, the code will jump to the appropriate part of the\n",
        "        file and then parse that section into a SeqRecord.\n",
        "        \n",
        "        Note that not all the input formats supported by Bio.SeqIO can be used\n",
        "        with this index function. It is designed to work only with sequential\n",
        "        file formats (e.g. \"fasta\", \"gb\", \"fastq\") and is not suitable for any\n",
        "        interlaced file format (e.g. alignment formats such as \"clustal\").\n",
        "        \n",
        "        For small files, it may be more efficient to use an in memory Python\n",
        "        dictionary, e.g.\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> records = SeqIO.to_dict(SeqIO.parse(open(\"Quality/example.fastq\"), \"fastq\"))\n",
        "        >>> len(records)\n",
        "        3\n",
        "        >>> sorted(records)\n",
        "        ['EAS54_6_R1_2_1_413_324', 'EAS54_6_R1_2_1_443_348', 'EAS54_6_R1_2_1_540_792']\n",
        "        >>> print(records[\"EAS54_6_R1_2_1_540_792\"].format(\"fasta\"))\n",
        "        >EAS54_6_R1_2_1_540_792\n",
        "        TTGGCAGGCCAAGGCCGATGGATCA\n",
        "        <BLANKLINE>\n",
        "        \n",
        "        As with the to_dict() function, by default the id string of each record\n",
        "        is used as the key. You can specify a callback function to transform\n",
        "        this (the record identifier string) into your preferred key. For example:\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> def make_tuple(identifier):\n",
        "        ...     parts = identifier.split(\"_\")\n",
        "        ...     return int(parts[-2]), int(parts[-1])\n",
        "        >>> records = SeqIO.index(\"Quality/example.fastq\", \"fastq\",\n",
        "        ...                       key_function=make_tuple)\n",
        "        >>> len(records)\n",
        "        3\n",
        "        >>> sorted(records)\n",
        "        [(413, 324), (443, 348), (540, 792)]\n",
        "        >>> print(records[(540, 792)].format(\"fasta\"))\n",
        "        >EAS54_6_R1_2_1_540_792\n",
        "        TTGGCAGGCCAAGGCCGATGGATCA\n",
        "        <BLANKLINE>\n",
        "        >>> (540, 792) in records\n",
        "        True\n",
        "        >>> \"EAS54_6_R1_2_1_540_792\" in records\n",
        "        False\n",
        "        >>> print(records.get(\"Missing\", None))\n",
        "        None\n",
        "        \n",
        "        Another common use case would be indexing an NCBI style FASTA file,\n",
        "        where you might want to extract the GI number from the FASTA identifer\n",
        "        to use as the dictionary key.\n",
        "        \n",
        "        Notice that unlike the to_dict() function, here the key_function does\n",
        "        not get given the full SeqRecord to use to generate the key. Doing so\n",
        "        would impose a severe performance penalty as it would require the file\n",
        "        to be completely parsed while building the index. Right now this is\n",
        "        usually avoided.\n",
        "        \n",
        "        See also: Bio.SeqIO.index_db() and Bio.SeqIO.to_dict()\n",
        "    \n",
        "    index_db(index_filename, filenames=None, format=None, alphabet=None, key_function=None)\n",
        "        Index several sequence files and return a dictionary like object.\n",
        "        \n",
        "        The index is stored in an SQLite database rather than in memory (as in the\n",
        "        Bio.SeqIO.index(...) function).\n",
        "        \n",
        "         - index_filename - Where to store the SQLite index\n",
        "         - filenames - list of strings specifying file(s) to be indexed, or when\n",
        "                      indexing a single file this can be given as a string.\n",
        "                      (optional if reloading an existing index, but must match)\n",
        "         - format   - lower case string describing the file format\n",
        "                      (optional if reloading an existing index, but must match)\n",
        "         - alphabet - optional Alphabet object, useful when the sequence type\n",
        "                      cannot be automatically inferred from the file itself\n",
        "                      (e.g. format=\"fasta\" or \"tab\")\n",
        "         - key_function - Optional callback function which when given a\n",
        "                      SeqRecord identifier string should return a unique\n",
        "                      key for the dictionary.\n",
        "        \n",
        "        This indexing function will return a dictionary like object, giving the\n",
        "        SeqRecord objects as values:\n",
        "        \n",
        "        >>> from Bio.Alphabet import generic_protein\n",
        "        >>> from Bio import SeqIO\n",
        "        >>> files = [\"GenBank/NC_000932.faa\", \"GenBank/NC_005816.faa\"]\n",
        "        >>> def get_gi(name):\n",
        "        ...     parts = name.split(\"|\")\n",
        "        ...     i = parts.index(\"gi\")\n",
        "        ...     assert i != -1\n",
        "        ...     return parts[i+1]\n",
        "        >>> idx_name = \":memory:\" #use an in memory SQLite DB for this test\n",
        "        >>> records = SeqIO.index_db(idx_name, files, \"fasta\", generic_protein, get_gi)\n",
        "        >>> len(records)\n",
        "        95\n",
        "        >>> records[\"7525076\"].description\n",
        "        'gi|7525076|ref|NP_051101.1| Ycf2 [Arabidopsis thaliana]'\n",
        "        >>> records[\"45478717\"].description\n",
        "        'gi|45478717|ref|NP_995572.1| pesticin [Yersinia pestis biovar Microtus str. 91001]'\n",
        "        \n",
        "        In this example the two files contain 85 and 10 records respectively.\n",
        "        \n",
        "        BGZF compressed files are supported, and detected automatically. Ordinary\n",
        "        GZIP compressed files are not supported.\n",
        "        \n",
        "        See also: Bio.SeqIO.index() and Bio.SeqIO.to_dict()\n",
        "    \n",
        "    parse(handle, format, alphabet=None)\n",
        "        Turns a sequence file into an iterator returning SeqRecords.\n",
        "        \n",
        "         - handle   - handle to the file, or the filename as a string\n",
        "                      (note older versions of Biopython only took a handle).\n",
        "         - format   - lower case string describing the file format.\n",
        "         - alphabet - optional Alphabet object, useful when the sequence type\n",
        "                      cannot be automatically inferred from the file itself\n",
        "                      (e.g. format=\"fasta\" or \"tab\")\n",
        "        \n",
        "        Typical usage, opening a file to read in, and looping over the record(s):\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> filename = \"Fasta/sweetpea.nu\"\n",
        "        >>> for record in SeqIO.parse(filename, \"fasta\"):\n",
        "        ...    print(\"ID %s\" % record.id)\n",
        "        ...    print(\"Sequence length %i\" % len(record))\n",
        "        ...    print(\"Sequence alphabet %s\" % record.seq.alphabet)\n",
        "        ID gi|3176602|gb|U78617.1|LOU78617\n",
        "        Sequence length 309\n",
        "        Sequence alphabet SingleLetterAlphabet()\n",
        "        \n",
        "        For file formats like FASTA where the alphabet cannot be determined, it\n",
        "        may be useful to specify the alphabet explicitly:\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> from Bio.Alphabet import generic_dna\n",
        "        >>> filename = \"Fasta/sweetpea.nu\"\n",
        "        >>> for record in SeqIO.parse(filename, \"fasta\", generic_dna):\n",
        "        ...    print(\"ID %s\" % record.id)\n",
        "        ...    print(\"Sequence length %i\" % len(record))\n",
        "        ...    print(\"Sequence alphabet %s\" % record.seq.alphabet)\n",
        "        ID gi|3176602|gb|U78617.1|LOU78617\n",
        "        Sequence length 309\n",
        "        Sequence alphabet DNAAlphabet()\n",
        "        \n",
        "        If you have a string 'data' containing the file contents, you must\n",
        "        first turn this into a handle in order to parse it:\n",
        "        \n",
        "        >>> data = \">Alpha\\nACCGGATGTA\\n>Beta\\nAGGCTCGGTTA\\n\"\n",
        "        >>> from Bio import SeqIO\n",
        "        >>> try:\n",
        "        ...     from StringIO import StringIO # Python 2\n",
        "        ... except ImportError:\n",
        "        ...     from io import StringIO # Python 3\n",
        "        ...\n",
        "        >>> for record in SeqIO.parse(StringIO(data), \"fasta\"):\n",
        "        ...     print(\"%s %s\" % (record.id, record.seq))\n",
        "        Alpha ACCGGATGTA\n",
        "        Beta AGGCTCGGTTA\n",
        "        \n",
        "        Use the Bio.SeqIO.read(...) function when you expect a single record\n",
        "        only.\n",
        "    \n",
        "    read(handle, format, alphabet=None)\n",
        "        Turns a sequence file into a single SeqRecord.\n",
        "        \n",
        "         - handle   - handle to the file, or the filename as a string\n",
        "                      (note older versions of Biopython only took a handle).\n",
        "         - format   - string describing the file format.\n",
        "         - alphabet - optional Alphabet object, useful when the sequence type\n",
        "                      cannot be automatically inferred from the file itself\n",
        "                      (e.g. format=\"fasta\" or \"tab\")\n",
        "        \n",
        "        This function is for use parsing sequence files containing\n",
        "        exactly one record.  For example, reading a GenBank file:\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> record = SeqIO.read(\"GenBank/arab1.gb\", \"genbank\")\n",
        "        >>> print(\"ID %s\" % record.id)\n",
        "        ID AC007323.5\n",
        "        >>> print(\"Sequence length %i\" % len(record))\n",
        "        Sequence length 86436\n",
        "        >>> print(\"Sequence alphabet %s\" % record.seq.alphabet)\n",
        "        Sequence alphabet IUPACAmbiguousDNA()\n",
        "        \n",
        "        If the handle contains no records, or more than one record,\n",
        "        an exception is raised.  For example:\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> record = SeqIO.read(\"GenBank/cor6_6.gb\", \"genbank\")\n",
        "        Traceback (most recent call last):\n",
        "            ...\n",
        "        ValueError: More than one record found in handle\n",
        "        \n",
        "        If however you want the first record from a file containing\n",
        "        multiple records this function would raise an exception (as\n",
        "        shown in the example above).  Instead use:\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> record = next(SeqIO.parse(\"GenBank/cor6_6.gb\", \"genbank\"))\n",
        "        >>> print(\"First record's ID %s\" % record.id)\n",
        "        First record's ID X55053.1\n",
        "        \n",
        "        Use the Bio.SeqIO.parse(handle, format) function if you want\n",
        "        to read multiple records from the handle.\n",
        "    \n",
        "    to_dict(sequences, key_function=None)\n",
        "        Turns a sequence iterator or list into a dictionary.\n",
        "        \n",
        "         - sequences  - An iterator that returns SeqRecord objects,\n",
        "                        or simply a list of SeqRecord objects.\n",
        "         - key_function - Optional callback function which when given a\n",
        "                        SeqRecord should return a unique key for the dictionary.\n",
        "        \n",
        "        e.g. key_function = lambda rec : rec.name\n",
        "        or,  key_function = lambda rec : rec.description.split()[0]\n",
        "        \n",
        "        If key_function is omitted then record.id is used, on the assumption\n",
        "        that the records objects returned are SeqRecords with a unique id.\n",
        "        \n",
        "        If there are duplicate keys, an error is raised.\n",
        "        \n",
        "        Example usage, defaulting to using the record.id as key:\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> filename = \"GenBank/cor6_6.gb\"\n",
        "        >>> format = \"genbank\"\n",
        "        >>> id_dict = SeqIO.to_dict(SeqIO.parse(filename, format))\n",
        "        >>> print(sorted(id_dict))\n",
        "        ['AF297471.1', 'AJ237582.1', 'L31939.1', 'M81224.1', 'X55053.1', 'X62281.1']\n",
        "        >>> print(id_dict[\"L31939.1\"].description)\n",
        "        Brassica rapa (clone bif72) kin mRNA, complete cds.\n",
        "        \n",
        "        A more complex example, using the key_function argument in order to\n",
        "        use a sequence checksum as the dictionary key:\n",
        "        \n",
        "        >>> from Bio import SeqIO\n",
        "        >>> from Bio.SeqUtils.CheckSum import seguid\n",
        "        >>> filename = \"GenBank/cor6_6.gb\"\n",
        "        >>> format = \"genbank\"\n",
        "        >>> seguid_dict = SeqIO.to_dict(SeqIO.parse(filename, format),\n",
        "        ...               key_function = lambda rec : seguid(rec.seq))\n",
        "        >>> for key, record in sorted(seguid_dict.items()):\n",
        "        ...     print(\"%s %s\" % (key, record.id))\n",
        "        /wQvmrl87QWcm9llO4/efg23Vgg AJ237582.1\n",
        "        BUg6YxXSKWEcFFH0L08JzaLGhQs L31939.1\n",
        "        SabZaA4V2eLE9/2Fm5FnyYy07J4 X55053.1\n",
        "        TtWsXo45S3ZclIBy4X/WJc39+CY M81224.1\n",
        "        l7gjJFE6W/S1jJn5+1ASrUKW/FA X62281.1\n",
        "        uVEYeAQSV5EDQOnFoeMmVea+Oow AF297471.1\n",
        "        \n",
        "        This approach is not suitable for very large sets of sequences, as all\n",
        "        the SeqRecord objects are held in memory. Instead, consider using the\n",
        "        Bio.SeqIO.index() function (if it supports your particular file format).\n",
        "    \n",
        "    write(sequences, handle, format)\n",
        "        Write complete set of sequences to a file.\n",
        "        \n",
        "         - sequences - A list (or iterator) of SeqRecord objects, or (if using\n",
        "                       Biopython 1.54 or later) a single SeqRecord.\n",
        "         - handle    - File handle object to write to, or filename as string\n",
        "                       (note older versions of Biopython only took a handle).\n",
        "         - format    - lower case string describing the file format to write.\n",
        "        \n",
        "        You should close the handle after calling this function.\n",
        "        \n",
        "        Returns the number of records written (as an integer).\n",
        "\n",
        "DATA\n",
        "    __docformat__ = 'epytext en'\n",
        "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Entrez.mail= \"daniel.epm12@gmail.com\"\n",
      "os.chdir(\"/home/tttt/MEGAsync/sistematica/proyecto/data/prueba_piloto/genomas/\")\n",
      "search_term = 'NC_007626.1[ACCESSION]'\n",
      "handle = Entrez.esearch(db='nucleotide', term=search_term)\n",
      "genome_ids = Entrez.read(handle)['IdList']\n",
      "\n",
      "for genome_id in genome_ids:\n",
      "    record = Entrez.efetch(db=\"nucleotide\", id=genome_id, rettype=\"gb\", retmode=\"text\")\n",
      "\n",
      "    filename = 'genBankRecord_{}.gb'.format(genome_id)\n",
      "    print('Writing:{}'.format(filename))\n",
      "    with open(filename, 'w') as f:\n",
      "        f.write(record.read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing:genBankRecord_83309099.gb\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Entrez.mail= \"daniel.epm12@gmail.com\"\n",
      "os.chdir(\"/home/tttt/MEGAsync/sistematica/proyecto/data/prueba_piloto/genomas/\")\n",
      "item = 'ATK1'\n",
      "animal = 'Homo sapien' \n",
      "search_string = item+\"[Gene] AND \"+animal+\"[Organism] AND mRNA[Filter] AND RefSeq[Filter]\"\n",
      "handle = Entrez.esearch(db=\"nucleotide\", term=search_string)\n",
      "record = Entrez.read(handle)\n",
      "ids = record['IdList']\n",
      "seq_id = ids[0] #you must implement an if to deal with <0 or >1 cases\n",
      "handle = Entrez.efetch(db=\"nucleotide\", id=seq_id, rettype=\"fasta\", retmode=\"text\")\n",
      "record = handleA.read()\n",
      "out_handle = open('myfasta.fasta', 'w')\n",
      "out_handle.write(record.rstrip('\\n'))\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-44-131bac7245cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IdList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mseq_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#you must implement an if to deal with <0 or >1 cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nucleotide\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrettype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fasta\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandleA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print handle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<addinfourl at 140101468517656 whose fp = <socket._fileobject object at 0x7f6c000c3650>>\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print search_string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ATK1[Gene] AND Homo sapien[Organism] AND mRNA[Filter] AND RefSeq[Filter]\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print search"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NC_000913 NC_002695 NC_011750 NC_011751 NC_017634 NC_018658\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print handle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<addinfourl at 140101468518160 whose fp = <socket._fileobject object at 0x7f6c000c3850>>\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print genome_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['83309099']\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import Entrez\n",
      " \n",
      "# ref.: http://wilke.openwetware.org/Parsing_Genbank_files_with_Biopython.html\n",
      " \n",
      "# replace with your real email (optional):\n",
      "Entrez.email = 'whatever@mail.com'\n",
      "# accession id works, returns genbank format, looks in the 'nucleotide' database:\n",
      "handle=Entrez.efetch(db='nucleotide',id='CP002059.1',rettype='gb')\n",
      "# store locally:\n",
      "local_file=open('CP002059.1.gb', 'w')\n",
      "local_file.write(handle.read())\n",
      "handle.close()\n",
      "local_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-51-dafcc793794e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# store locally:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlocal_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CP002059.1.gb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlocal_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlocal_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    610\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m                 \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mchunk_left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;31m# fragmentation issues on many platforms.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Entrez.mail= \"daniel.epm12@gmail.com\"\n",
      "os.chdir(\"/home/tttt/MEGAsync/sistematica/proyecto/data/prueba_piloto/genomas/\")\n",
      "# Imports\n",
      "from Bio import Entrez\n",
      "from Bio import SeqIO\n",
      "\n",
      "#############################\n",
      "# Retrieve NCBI Data Online #\n",
      "#############################\n",
      "\n",
      "Entrez.email     = \"daniel.epm12@gmail.com\"             # Always tell NCBI who you are\n",
      "genomeAccessions = ['NC_007626.1']\n",
      "search           = \" \".join(genomeAccessions)\n",
      "handle           = Entrez.read(Entrez.esearch(db=\"nucleotide\", term=search, retmode=\"xml\"))\n",
      "genomeIds        = handle['IdList']\n",
      "records          = Entrez.efetch(db=\"nucleotide\", id=genomeIds, rettype=\"gb\", retmode=\"text\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "addinfourl instance has no attribute '__getitem__'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-62-93955ac6ddea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msearch\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenomeAccessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mhandle\u001b[0m           \u001b[0;34m=\u001b[0m\u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nucleotide'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenomeAccessions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrettype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgenomeIds\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IdList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mrecords\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nucleotide\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenomeIds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrettype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: addinfourl instance has no attribute '__getitem__'"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print records"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<addinfourl at 140101463059920 whose fp = <socket._fileobject object at 0x7f6c0a464250>>\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print handle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'Count': '6', u'RetMax': '6', u'IdList': ['556503834', '15829254', '218698419', '218703261', '387615344', '407479587'], u'TranslationSet': [], u'RetStart': '0', u'QueryTranslation': ''}\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "'NC_000913 NC_002695 NC_011750 NC_011751 NC_017634 NC_018658'"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import Entrez\n",
      "Entrez.email = \"daniel.epm12@gmail.com\"     # Always tell NCBI who you are\n",
      "handle = Entrez.efetch(db=\"nucleotide\", id=\"NC_007626.1\", rettype=\"gb\", retmode=\"fasta\")\n",
      "print(handle.read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LOCUS       NC_007626            4967148 bp    DNA     circular CON 24-FEB-2015\n",
        "DEFINITION  Magnetospirillum magneticum AMB-1 DNA, complete genome.\n",
        "ACCESSION   NC_007626\n",
        "VERSION     NC_007626.1  GI:83309099\n",
        "DBLINK      BioProject: PRJNA224116\n",
        "            Assembly: GCF_000009985.1\n",
        "KEYWORDS    RefSeq.\n",
        "SOURCE      Magnetospirillum magneticum AMB-1\n",
        "  ORGANISM  Magnetospirillum magneticum AMB-1\n",
        "            Bacteria; Proteobacteria; Alphaproteobacteria; Rhodospirillales;\n",
        "            Rhodospirillaceae; Magnetospirillum.\n",
        "REFERENCE   1\n",
        "  AUTHORS   Matsunaga,T., Okamura,Y., Fukuda,Y., Wahyudi,A.T., Murase,Y. and\n",
        "            Takeyama,H.\n",
        "  TITLE     Complete genome sequence of the facultative anaerobic magnetotactic\n",
        "            bacterium Magnetospirillum sp. strain AMB-1\n",
        "  JOURNAL   DNA Res. 12 (3), 157-166 (2005)\n",
        "   PUBMED   16303747\n",
        "REFERENCE   2  (bases 1 to 4967148)\n",
        "  AUTHORS   Matsunaga,T., Okamura,Y., Fukuda,Y. and Takeyama,H.\n",
        "  TITLE     Direct Submission\n",
        "  JOURNAL   Submitted (06-SEP-2004) Contact:Tadashi Matsunaga Tokyo University\n",
        "            of Agriculture and Technology, Department of Biotechnology;\n",
        "            Naka-cho 2-24-16, Koganei, Tokyo 184-8588, Japan\n",
        "COMMENT     VALIDATED REFSEQ: This record has undergone validation or\n",
        "            preliminary review.\n",
        "            Annotation was added by the NCBI Prokaryotic Genome Annotation\n",
        "            Pipeline (released 2013). Information about the Pipeline can be\n",
        "            found here: http://www.ncbi.nlm.nih.gov/genome/annotation_prok/\n",
        "            \n",
        "            ##Genome-Annotation-Data-START##\n",
        "            Annotation Provider          :: NCBI\n",
        "            Annotation Date              :: 01/16/2015 10:24:23\n",
        "            Annotation Pipeline          :: NCBI Prokaryotic Genome Annotation\n",
        "                                            Pipeline\n",
        "            Annotation Method            :: Best-placed reference protein set;\n",
        "                                            GeneMarkS+\n",
        "            Annotation Software revision :: 2.9 (rev. 456760)\n",
        "            Features Annotated           :: Gene; CDS; rRNA; tRNA; ncRNA;\n",
        "                                            repeat_region\n",
        "            Genes                        :: 4,615\n",
        "            CDS                          :: 4,506\n",
        "            Pseudo Genes                 :: 53\n",
        "            rRNAs                        :: 6 ( 5S, 16S, 23S )\n",
        "            tRNAs                        :: 49\n",
        "            ncRNA                        :: 1\n",
        "            Frameshifted Genes           :: 47\n",
        "            ##Genome-Annotation-Data-END##\n",
        "            COMPLETENESS: full length.\n",
        "FEATURES             Location/Qualifiers\n",
        "     source          1..4967148\n",
        "                     /organism=\"Magnetospirillum magneticum AMB-1\"\n",
        "                     /mol_type=\"genomic DNA\"\n",
        "                     /strain=\"AMB-1\"\n",
        "                     /db_xref=\"taxon:342108\"\n",
        "CONTIG      join(AP007255.1:1..4967148)\n",
        "//\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import Entrez, SeqIO\n",
      "handle = Entrez.efetch(db=\"nucleotide\", id=\"NC_007626\", rettype=\"gb\", retmode=\"text\")\n",
      "record = SeqIO.read(handle, \"genbank\")\n",
      "handle.close()\n",
      "print(record)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ID: NC_007626.1\n",
        "Name: NC_007626\n",
        "Description: Magnetospirillum magneticum AMB-1 DNA, complete genome.\n",
        "Database cross-references: BioProject:PRJNA224116 Assembly:GCF_000009985.1\n",
        "Number of features: 1\n",
        "/comment=VALIDATED REFSEQ: This record has undergone validation or\n",
        "preliminary review.\n",
        "Annotation was added by the NCBI Prokaryotic Genome Annotation\n",
        "Pipeline (released 2013). Information about the Pipeline can be\n",
        "found here: http://www.ncbi.nlm.nih.gov/genome/annotation_prok/\n",
        "##Genome-Annotation-Data-START##\n",
        "Annotation Provider          :: NCBI\n",
        "Annotation Date              :: 01/16/2015 10:24:23\n",
        "Annotation Pipeline          :: NCBI Prokaryotic Genome Annotation\n",
        "                                Pipeline\n",
        "Annotation Method            :: Best-placed reference protein set;\n",
        "                                GeneMarkS+\n",
        "Annotation Software revision :: 2.9 (rev. 456760)\n",
        "Features Annotated           :: Gene; CDS; rRNA; tRNA; ncRNA;\n",
        "                                repeat_region\n",
        "Genes                        :: 4,615\n",
        "CDS                          :: 4,506\n",
        "Pseudo Genes                 :: 53\n",
        "rRNAs                        :: 6 ( 5S, 16S, 23S )\n",
        "tRNAs                        :: 49\n",
        "ncRNA                        :: 1\n",
        "Frameshifted Genes           :: 47\n",
        "##Genome-Annotation-Data-END##\n",
        "COMPLETENESS: full length.\n",
        "/sequence_version=1\n",
        "/source=Magnetospirillum magneticum AMB-1\n",
        "/taxonomy=['Bacteria', 'Proteobacteria', 'Alphaproteobacteria', 'Rhodospirillales', 'Rhodospirillaceae', 'Magnetospirillum']\n",
        "/keywords=['RefSeq']\n",
        "/references=[Reference(title='Complete genome sequence of the facultative anaerobic magnetotactic bacterium Magnetospirillum sp. strain AMB-1', ...), Reference(title='Direct Submission', ...)]\n",
        "/accessions=['NC_007626']\n",
        "/data_file_division=CON\n",
        "/date=24-FEB-2015\n",
        "/contig=join(AP007255.1:1..4967148)\n",
        "/organism=Magnetospirillum magneticum AMB-1\n",
        "/gi=83309099\n",
        "UnknownSeq(4967148, alphabet = IUPACAmbiguousDNA(), character = 'N')\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}